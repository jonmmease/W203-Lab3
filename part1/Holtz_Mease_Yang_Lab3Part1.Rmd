---
title: "W203 Lab 3, Part 1: Reducing Crime"
author:
- Stephen Holtz
- Jon Mease
- Hong Yang

output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Introduction and Research Question
As members of...

## Initial Data Loading and Cleaning
First we will load and examine the data set.
```{r}
library(car)
crime_raw <- read.csv("../data/crime_v2.csv")
```

We note that the last 6 rows of the dataset are `NA` in all columns except `prbconv`. According to the codebook `prbconv` is a numeric variable representing the probability of conviction, but it has been loaded as a factor due to the presence of a backtick string character present in row 97.

```{r}
tail(crime_raw[,1:6], 10)
```

We remove last 6 rows from `crime_raw` and create a new data frame `crime` and convert `prbconv` from a factor into a numeric column.
```{r}
crime <- crime_raw[1:(nrow(crime_raw)-6),]
crime$prbconv <- as.numeric(levels(crime$prbconv)[crime$prbconv])
```

Next we examine the probability variables `prbarr`, `prbconv`, `prbpris`

```{r}
summary(crime[,c('prbarr', 'prbconv', 'prbpris')])
```
Here we see that all probability values are non-negative, but `prbarr` and `prbconv` each have values that are greater than one and therefore not valid probabilities. However, the codebook states that "the probability of arrest is proxied by the ratio of arrests to offenses" and "the probability of conviction is proxied by the ratio of convictions to arrests". By these caclulations, it is plausible that these probability proxy variables will have values larger than one, so we do not remove these observations at this time.

Next, we identified an unreasonably anonymous value for the service industry wage, `wser`, in row 84 for county 185.

```{r}
plot(crime$wser, main = 'Service industry weekly wage')
```

This extreme value (2177.0681) is 860% of the median (253.2) and 556% of the second largest wage in the dataset (391.3081).  Since the other remaining properties for this observation are all in reasonable ranges, with respect to the other observations in the sample, we will replace the anomolous value with `NA` rather than remove the entire observation.

```{r}
crime$wser[84] = NA
```


There is also an unreasonably low density value which we can identify by ploting density on a log scale.

```{r}
plot(log(crime$density), main = 'Population density (people per square mile)')
```

This value value of 0.0000203422. The entire state of North Caroline is 53,819 $mi^2$, and if the entire state had this population density there would be only 1.09 persons in the entire state!  Therefore a country that is a small fraction the size of the entire state that had this density would have less than one person living in it.

```{r}
crime$density[79] = NA
```


## The Model Building Process (Jon)

We will use the reported crime rate, `crmrte`, as our outcome variable.

### Outcome variabel: `crmrte`

```{r}
summary(crime$crmrte)
```

The mean is a bit larger than the median indicating a moderate positive skew.

```{r}
hist(crime$crmrte)
```

The histogram of `crmrte` confirms the skew and also shows that the distribution of `crmrte` is uniodal.

### Explanatory variable: `density`
Next we examine potential explanatory variables.  We start `density`, the number of persons per square mile.

```{r}
summary(crime$density)
```

Here the median is almost 1.5 times larger than the median, indicating a significant positive skew.

```{r}
hist(crime$density, breaks = 15)
```

The histogram of `density` confirms the large positive skew and shows that it has a unimodal distribution peaked at around 0.5-1.0 persons per square mile.


```{r}
plot(crime$density, crime$crmrte)
abline(lm(crime$crmrte ~ crime$density))
```

Based on the scatter plot, there appears to be a positive relationship between population density and crime rate.  The relationship is clearer and more symetric about the best-fit line in log-log space.

```{r}
plot(log(crime$density), log(crime$crmrte))
abline(lm(log(crime$crmrte) ~ log(crime$density)))
```

### Explanatory variable: `prbarr`
Next we look at the probability of arrest (`prbarr`).

```{r}
summary(crime$prbarr)
```
The median is slightly larger than the mean, indicating a slight positive skew to the distribution.

```{r}
hist(crime$prbarr, breaks = 15)
```
The histogram shows that the distribution is unimodal, and that the slight positive skew is largely due to two outlying values. Taking the log transform removes the skew altogether

```{r}
hist(log(crime$prbarr), breaks = 15)
```

```{r}
plot(crime$prbarr, crime$crmrte)
abline(lm(crime$crmrte ~ crime$prbarr))
```

The relationship between the log of the probability of arrest and crime rate appears to be a bit more linear, so we will keep this transformation.
```{r}
plot(log(crime$prbarr), log(crime$crmrte))
abline(lm(log(crime$crmrte) ~ log(crime$prbarr)))
```


```{r}
plot(crime$pctymle, log(crime$crmrte))
abline(lm(log(crime$crmrte) ~ crime$pctymle))
```

```{r}
plot(crime$pctmin80, log(crime$crmrte))
abline(lm(log(crime$crmrte) ~ crime$pctmin80))
```

TODO: Add discussion of rational for choosing these outcome and explanatory variables based on the research question. 

```{r}
plot(log(crime$pctymle), log(crime$crmrte))
abline(lm(log(crime$crmrte) ~ log(crime$pctymle)))
```

## The Model Building Process

## Regression Models (Jon)


Model with only the explanatory variables of key interest

```{r}
model1 <- lm(log(crime$crmrte) ~  log(crime$density) + log(crime$pctmin80))
summary(model1)
```

Model that includes key explanatory variables and only covariates that you believe increase the accuracy of your results without introducing substantial bias.

```{r}
model2 <- lm(log(crime$crmrte) ~  log(crime$density) + log(crime$pctmin80) + log(crime$prbconv) + log(crime$prbarr) + log(crime$polpc))
summary(model2)
```

One model that includes the previous covariates, and most, if not all, other covariates

```{r}
model3 <- lm(log(crime$crmrte) ~  log(crime$density) + log(crime$pctmin80) + log(crime$prbconv) + log(crime$prbarr) + log(crime$polpc) + crime$central + log(crime$prbpris) + log(crime$avgsen)
             + log(crime$wcon) + log(crime$wser) + log(crime$wmfg) + log(crime$wloc) + log(crime$taxpc) + crime$urban )
summary(model3)
```

```{r}
library(stargazer)
stargazer(model1, model2, model3, type='text')
```

### Observations
 - The predictive power of pctmin80 is very stable as additional factors are added to the model. Appears to be orthogonal to other features
 - Predictive power of density is decreased some when prob arrest/conviction are added to the model (There is some colinearity between density and these values)
 - prob arrest and conviction are not very correlated with each other and each independently is associated with a decrease in crime
 - 

TODO: interpret
TODO: State/Evaluate CLM assumptions.

## Omitted Variables Discussion
Need some discussion about `pctmin80` result. We don't have information on the demographics of those being convicted of crimes, 

And `polpc` influence is counterintuitive. Why is there a positive relationship between police per capita and crime?

## Conclusion
Political platform of pushing for more/faster arrest/convictions with no or shorter prison sentences. Deterrent seems to be in arrest/conviction, not as much in being sent to prison, or based on how long a prison sentence is.

Further studies needed to understand
