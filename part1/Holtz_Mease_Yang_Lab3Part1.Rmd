---
title: "W203 Lab 3, Part 1: Reducing Crime"
author:
- Stephen Holtz
- Jon Mease
- Hong Yang

output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Introduction and Research Question
As members of Berkeley Analytica, a political consultancy,
we seek to inform political operatives on what policy decisions
could be most useful once they take office. We also seek to 
help inform their campaigns so they can offer voters a sincere, 
intellectually honest, and meaningful vision for how a candidate 
or party could change society. 

In this project, we are applying a cross section of data from 
C. Cornwell and W. Trumball (1994), "Estimating the Economic Model
of Crime with Panel Data," Review of Economics and Statistics. 
The primary objective of this project is to inform policy makers of the 
value of laws and funding decisions viewed through the lens of reducing
crime. Specific policy questions include, providing funding for more 
police officers; setting guidance or requirements for sentencing of criminals;
implementing policies that improve the distribution of minorities across 
neighborhoods; and implimenting policies that keep young males occupued and
out of trouble. 
The secondary objective of this project will be to identify other factors
that affect crime that policy makers could account for in formulating a 
strategy to reduce crime. 

## Initial Data Loading and Cleaning
First we will load and examine the data set.
```{r}
library(car)
install.packages("stargazer")
library(stargazer)
setwd("C:/Users/Holtz/Documents/Berkeley/203 Stats & R/Lab 3")
getwd()
crime_raw <- read.csv("crime_v2.csv")
```

We note that the last 6 rows of the dataset are `NA` in all columns except `prbconv`. According to the codebook `prbconv` is a numeric variable representing the probability of conviction, but it has been loaded as a factor due to the presence of a backtick string character present in row 97.

```{r}
tail(crime_raw[,1:6], 10)
```

We remove last 6 rows from `crime_raw` and create a new data frame `crime` and convert `prbconv` from a factor into a numeric column.
```{r}
crime <- crime_raw[1:(nrow(crime_raw)-6),]
crime$prbconv <- as.numeric(levels(crime$prbconv)[crime$prbconv])
```

Next we examine the probability variables `prbarr`, `prbconv`, `prbpris`

```{r}
summary(crime[,c('prbarr', 'prbconv', 'prbpris')])
```
Here we see that all probability values are non-negative, but `prbarr` and `prbconv` each have values that are greater than one and therefore not valid probabilities. However, the codebook states that "the probability of arrest is proxied by the ratio of arrests to offenses" and "the probability of conviction is proxied by the ratio of convictions to arrests". By these caclulations, it is plausible that these probability proxy variables will have values larger than one, so we do not remove these observations at this time.

Next, we identified an unreasonably anomalous value for the service industry wage, `wser`, in row 84 for county 185.

```{r}
plot(crime$wser, main = 'Service industry weekly wage')
```

This extreme value (2177.0681) is 860% of the median (253.2) and 556% of the second largest wage in the dataset (391.3081).  Since the other remaining properties for this observation are all in reasonable ranges, with respect to the other observations in the sample, we will replace the anomolous value with `NA` rather than remove the entire observation.

```{r}
crime$wser[84] = NA
```


There is also an unreasonably low density value which we can identify by ploting density on a log scale.

```{r}
plot(log(crime$density), main = 'Population density (people per square mile)')
```

This value value of 0.0000203422. The entire state of North Caroline is 53,819 $mi^2$, and if the entire state had this population density there would be only 1.09 persons in the entire state!  Therefore a country that is a small fraction the size of the entire state that had this density would have less than one person living in it.

```{r}
crime$density[79] = NA
```
## The Model Building Process

We will use the reported crime rate, `crmrte`, as our outcome variable.

### Outcome variabel: `crmrte`

```{r}
summary(crime$crmrte)
```

The mean is a bit larger than the median indicating a moderate positive skew.

```{r}
hist(crime$crmrte)
```

The histogram of `crmrte` confirms the skew and also shows that the distribution of `crmrte` is uniodal.

### Explanatory variable: `density`
Next we examine potential explanatory variables.  We start `density`, the number of persons per square mile.

```{r}
summary(crime$density)
```

Here the median is almost 1.5 times larger than the median, indicating a significant positive skew.

```{r}
hist(crime$density, breaks = 15)
```

The histogram of `density` confirms the large positive skew and shows that it has a unimodal distribution peaked at around 0.5-1.0 persons per square mile.


```{r}
plot(crime$density, crime$crmrte)
abline(lm(crime$crmrte ~ crime$density))
```

Based on the scatter plot, there appears to be a positive relationship between population density and crime rate.  The relationship is clearer and more symetric about the best-fit line in log-log space.

```{r}
plot(log(crime$density), log(crime$crmrte))
abline(lm(log(crime$crmrte) ~ log(crime$density)))
```

### Explanatory variable: `prbarr`
Next we look at the probability of arrest (`prbarr`).

```{r}
summary(crime$prbarr)
```
The median is slightly larger than the mean, indicating a slight positive skew to the distribution.

```{r}
hist(crime$prbarr, breaks = 15)
```
The histogram shows that the distribution is unimodal, and that the slight positive skew is largely due to two outlying values. Taking the log transform removes the skew altogether

```{r}
hist(log(crime$prbarr), breaks = 15)
```

```{r}
plot(crime$prbarr, crime$crmrte)
abline(lm(crime$crmrte ~ crime$prbarr))
```

The relationship between the log of the probability of arrest and crime rate appears to be a bit more linear, so we will keep this transformation.
```{r}
plot(log(crime$prbarr), log(crime$crmrte))
abline(lm(log(crime$crmrte) ~ log(crime$prbarr)))
```


```{r}
plot(crime$pctymle, log(crime$crmrte))
abline(lm(log(crime$crmrte) ~ crime$pctymle))
```

```{r}
plot(crime$pctmin80, log(crime$crmrte))
abline(lm(log(crime$crmrte) ~ crime$pctmin80))
```


# Because we are working for a political campaign we want to investigate parameters that will inform
# policy decisions once the political party is in power, as well as the platform that the campaign
# will use to get elected.
# Based on that premise, and because density is the single most predictive paramter in the dataset,
# we want to investigate the effects of population density on crime. 
# Similarly, we believe that probability of arrest is worth investigating as it will inform
# policy decisions and the platform on whether or not more funding should be put into having more police 
# officers. 
# Furthermore, the population of young males and the percentage of minorities in a population need to 
# be addressed as those appear to receive political focus already, and the campaign should be aware of 
# the actual relationships between those variables and crime rates. For policy makers, the correlation
# between minorities and crime could be useful evidence to support policies that would lead to 
# greater integration of cultural groups into
# every neighborhood. 
# Similarly, a relationship between young males and crime could be used to justify funding for programs
# that help young males stay occupied and away from criminal elements.

```{r}
plot(log(crime$pctymle), log(crime$crmrte))
abline(lm(log(crime$crmrte) ~ log(crime$pctymle)))
```

## The Model Building Process

## Regression Models

### Model 1
Model with only the explanatory variables of key interest.

prbarr(because lower chance of arrest can lead to more crime)
prbconv and prbpris (for similar reason as prbarr)
polpc has strong positive correlation with prbarr, pctmin80 is included for the reason of political campaign.

```{r}
scatterplotMatrix(~log(crmrte)+log(prbarr), data = crime)
```

```{r}
scatterplotMatrix(~log(crmrte)+log(polpc), data = crime)
```

```{r}
(Model1 <- lm(log(crmrte) ~ log(prbarr) + prbconv + prbpris + log(polpc) + pctmin80, data=crime))
summary(Model1)
```

```{r}
plot(Model1$fitted.values, Model1$residuals)
```

## Model 1 Discussion
Model 1 includes the explanatory variables of key interest to the political 
campaign: 
1. Probability of Arrest, transformed by taking the log
2. Probability of Conviction
3. Probability of Prison
4. Police Per Capita, transformed by taking the log
These variables were selected as they are factors that a political operative
can influence, once they are in power. The average sentence length was 
omitted purposely because it did not have a meaningful correlation with crime
rates. This observation is valuable for policy-makers as it could permit
better decision making with respect to allocation of funds.

### Model 2
adding density, wfed and wser to the key explanatory variables.
Density and urban are problematic, due to multicollinearity, correlation = .82
Wages - one type goes up the other type tends to go up, they can tend to split the effect among themselves. There is considerable amount of multicollinearity among the different wages.
Also density and wages have some multicollinearity, which make sense since jobs in the city tend to have higher wages.
Residuals apprear to be centered at 0, also we donâ€™t see any patterns in the residuals

```{r}
(Model2 = lm(log(crmrte) ~ log(prbarr) + prbconv + prbpris + log(polpc) + pctmin80 + log(density) + wfed + wser, data = crime))
summary(Model2)$r.square
summary(Model2)
```

```{r}
plot(Model2$fitted.values, Model2$residuals)
```

## Model 2 Discussion
Model 2 includes the following terms:
1. Log of probability of arrest
2. Probability of conviction
3. Log of Police Per Capita
4. Percent Minority
5. Log of density
6. Average wage of federal employees
7. Average wage of service industry employees

The log of density term was added to Model 2 to improve accuracy
because the exploratory data analysis revealed that there is a
positive correlation between density and crime rate. This correlation
has been noted by other researchers (Geoffrey West in "Scale: The Universal 
Laws of Growth, Innovation, Sustainability, and the Pace of Life in 
Organisms, Cities, Economies, and Companies"). This is a useful variable as 
policy makers could encourage development and housing policies that lead 
to lower population density such as improving transit options to suburban 
areas. 

The average wage of federal employees was included as it was expected to
add a degree of further accuracy to the model, but as most of the wage terms
were colinear with density, most of the other wage terms were omitted purposely.

The average wage of the service industry was included because among the
wage variables it was unique for being negatively correlated with crime
rates. Policy makers could view this as evidence for the value of increasing
the minimum wage in the hopes of reducing crime.

```{r}
(Model2.1 = lm(log(crmrte) ~ log(prbarr) + prbconv + prbpris + log(polpc) + pctmin80 + urban, data = crime))
summary(Model2.1)$r.square
```
Model2.1 was created to confirm if 'urban' was a better 
variable to use than 'density' as the two are colinear.
Model2.1 is less accurate than Model2, so we will continue with 
Model2.

### Model 3

```{r}
(Model3 = lm(log(crmrte) ~ log(prbarr) + prbconv + prbpris + log(polpc) + pctmin80 + log(density) + wser + county + avgsen + taxpc + wcon + wtuc + wtrd + wfir + wmfg + wfed + wsta + wloc + mix + pctymle, data = crime))
summary(Model3)$r.square
```

```{r}
plot(Model3$fitted.values, Model3$residuals)
```

## Model 3 Discussion
Model 3 was constructed using every variable with the exception of the "west", "central", and "urban"
variables. The analysts believed that these variables are already correlated with density and 
they do not have any intrinsic value in informing policy. 
By including all the remaining variables, the r-squared value of Model 3 improved by 
4.39 percentage points over Model 2. This compares with a 12 percentage point improvement between
Model 2 and Model 1. 
The analysts at Berkeley Analytica conclude that the improved fit of Model 3 is not justified 
by the additional data. In short, Model 2 is more valueable as Model 3 may be approaching over-fitting.

### Models Table

```{r}
stargazer(Model1, Model2, Model2.1, Model3, type = "text", 
          report = "vc", # Don't report errors, since we haven't covered them
          title = "Linear Models Predicting Crime Rate",
          keep.stat = c("rsq", "n"),
          omit.table.layout = "n",
          header=FALSE) # Omit more output related to errors
```

```

### Observations
 - The predictive power of pctmin80 is very stable as additional factors are added to the model. Appears to be orthogonal to other features
 - Predictive power of density is decreased some when prob arrest/conviction are added to the model (There is some colinearity between density and these values)
 - prob arrest and conviction are not very correlated with each other and each independently is associated with a decrease in crime
 - polpc correlates positively with ave sentence.


## Omitted Variables Discussion
Need some discussion about `pctmin80` result. We don't have information on the demographics of those being convicted of crimes, 

And `polpc` influence is counterintuitive. Why is there a positive relationship between police per capita and crime?

## Conclusion
Political platform of pushing for more/faster arrest/convictions with no or shorter prison sentences. Deterrent seems to be in arrest/conviction, not as much in being sent to prison, or based on how long a prison sentence is.

Further studies needed to understand
